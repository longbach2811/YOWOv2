{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 root_dir, \n",
    "                 dataset = 'custom',\n",
    "                 img_size = 224,\n",
    "                 transform=None,\n",
    "                 is_train = False,\n",
    "                 len_clip=16,\n",
    "                 split_ratio=0.8,\n",
    "                 sampling_rate=1):\n",
    "        self.root_dir = root_dir\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "        self.img_size = img_size\n",
    "        self.len_clip = len_clip\n",
    "        self.is_train = is_train\n",
    "        self.sampling_rate = sampling_rate\n",
    "        \n",
    "        \n",
    "        self.classes = self.load_classes(os.path.join(root_dir, 'classes.txt'))\n",
    "        self.samples = self.load_samples()\n",
    "\n",
    "        self.train_size = int(split_ratio * len(self.samples))\n",
    "        self.train_dataset, self.test_dataset = self.samples[:self.train_size], self.samples[self.train_size:]\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.is_train:\n",
    "            return len(self.train_dataset)\n",
    "        else:\n",
    "            return len(self.test_dataset)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame_idx, video_clip, target = self.pull_item(idx)\n",
    "\n",
    "        return frame_idx, video_clip, target\n",
    "    \n",
    "    def pull_item(self, idx):\n",
    "        if self.is_train:\n",
    "            img_path, label_path = self.train_dataset[idx]\n",
    "            d = random.randint(1, 2)\n",
    "            max_num = len(self.train_dataset)\n",
    "        else:\n",
    "            img_path, label_path = self.test_dataset[idx]\n",
    "            d = self.sampling_rate\n",
    "            max_num = len(self.train_dataset)\n",
    "        img_split = label_path.split(\"/\")\n",
    "        img_id = img_split[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "        video_clip = []\n",
    "        for i in reversed(range(self.len_clip)):\n",
    "            img_id_temp = int(img_id) - i * d\n",
    "            if img_id_temp < 1:\n",
    "                img_id_temp = 1\n",
    "            elif img_id_temp > max_num:\n",
    "                img_id_temp = max_num\n",
    "            \n",
    "            frame = Image.open(img_path).convert('RGB')\n",
    "\n",
    "            if self.transform:\n",
    "                frame = self.transform(frame)\n",
    "            ow, oh = frame.size(2), frame.size(1)\n",
    "            # ow, oh = frame.width, frame.height\n",
    "\n",
    "\n",
    "\n",
    "            video_clip.append(frame)\n",
    "\n",
    "            frame_id = f\"{img_split[6]}_{img_split[7]}_{img_split[8]}\"\n",
    "        \n",
    "        if os.path.getsize(label_path):\n",
    "            target = np.loadtxt(label_path)\n",
    "        else:\n",
    "            target = None \n",
    "\n",
    "        label = target[..., :1]\n",
    "        # print('label', label)\n",
    "        boxes = target[..., 1:]\n",
    "        # print('boxes', boxes)\n",
    "        target = np.concatenate([boxes, label], axis=-1).reshape(-1, 5)  \n",
    "        # print('target', target)\n",
    "        # print('bbox', target[:, :4])\n",
    "        # print('labels', target[:, -1])\n",
    "        \n",
    "        target = torch.as_tensor(target).float()\n",
    "        \n",
    "        # transform\n",
    "        # video_clip, target = self.transform(video_clip, target)\n",
    "        # List [T, 3, H, W] -> [3, T, H, W]\n",
    "        video_clip = torch.stack(video_clip, dim=1)\n",
    "        # print(\"Video clip shape\", video_clip.shape)\n",
    "\n",
    "        # reformat target\n",
    "        target = {\n",
    "            'boxes': target[:, :4].float(),      # [N, 4]\n",
    "            'labels': target[:, -1].long(),    # [N,]\n",
    "            'orig_size': [ow, oh],\n",
    "            'video_idx':frame_id\n",
    "            }\n",
    "\n",
    "        # print(target)\n",
    "\n",
    "        return frame_id, video_clip, target     \n",
    "        \n",
    "        \n",
    "\n",
    "    def load_classes(self, classes_file):\n",
    "        with open(classes_file, 'r') as file: \n",
    "            classes = [line.strip() for line in file.readlines()]\n",
    "            self.num_classes = len(classes)\n",
    "            return classes\n",
    "        \n",
    "\n",
    "    def load_samples(self):\n",
    "        samples = []\n",
    "\n",
    "        for class_folder in os.listdir(self.root_dir):\n",
    "            class_folder_path = os.path.join(self.root_dir, class_folder)\n",
    "            # print(\"class_folder_path: \", class_folder_path)\n",
    "            if os.path.isdir(class_folder_path):\n",
    "                data_folder_path = os.path.join(class_folder_path, \"labels\")\n",
    "                # print(\"data folder path:\", data_folder_path)\n",
    "                for file in os.listdir(data_folder_path):\n",
    "                    if file.endswith(\".txt\"):\n",
    "                        frame_num = file.split(\"_\")[-1].split(\".\")[0]\n",
    "                        label_path = os.path.join(data_folder_path, file)\n",
    "                        img_path = os.path.join(class_folder_path, \"images\", f\"frame_{frame_num}.jpg\")\n",
    "                        # print(img_path, label_path)\n",
    "                        if os.path.exists(label_path) and os.path.exists(img_path):\n",
    "                            samples.append((img_path, label_path))\n",
    "        # print(len(samples))               \n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollateFunc(object):\n",
    "    def __call__(self, batch):\n",
    "        batch_frame_id = []\n",
    "        batch_key_target = []\n",
    "        batch_video_clips = []\n",
    "\n",
    "        for sample in batch:\n",
    "            key_frame_id = sample[0]\n",
    "            video_clip = sample[1]\n",
    "            key_target = sample[2]\n",
    "            \n",
    "            batch_frame_id.append(key_frame_id)\n",
    "            batch_video_clips.append(video_clip)\n",
    "            batch_key_target.append(key_target)\n",
    "\n",
    "        # List [B, 3, T, H, W] -> [B, 3, T, H, W]\n",
    "        batch_video_clips = torch.stack(batch_video_clips)\n",
    "        \n",
    "        return batch_frame_id, batch_video_clips, batch_key_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = CollateFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.setNumThreads(0)\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "from utils import distributed_utils\n",
    "from utils.com_flops_params import FLOPs_and_Params\n",
    "from utils.solver.optimizer import build_optimizer\n",
    "from utils.solver.warmup_schedule import build_warmup\n",
    "\n",
    "from config import build_dataset_config, build_model_config\n",
    "from models import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    batch_size = 8\n",
    "    cuda = False\n",
    "    save_folder = \"./checkpoint/custom\"\n",
    "    dataset = \"custom_dataset\"\n",
    "    version = \"yowo_v2_large\"\n",
    "    loss_conf_weight = 1\n",
    "    loss_cls_weight = 1\n",
    "    loss_reg_weight = 5\n",
    "    topk_candicate = 10\n",
    "    center_sampling_radius = 2.5\n",
    "    sybn = False\n",
    "    focal_loss = False\n",
    "    freeze_backbone_2d = False\n",
    "    freeze_backbone_3d = False\n",
    "    distributed = False\n",
    "    resume = None\n",
    "    topk = 16\n",
    "    base_lr = 1e-5\n",
    "    len_clip = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World size: 1\n"
     ]
    }
   ],
   "source": [
    "world_size = distributed_utils.get_world_size()\n",
    "per_gpu_batch = args.batch_size // world_size\n",
    "print('World size: {}'.format(world_size))\n",
    "if args.distributed:\n",
    "    distributed_utils.init_distributed_mode(args)\n",
    "    print(\"git:\\n  {}\\n\".format(distributed_utils.get_sha()))\n",
    "\n",
    "# path to save model\n",
    "path_to_save = os.path.join(args.save_folder, args.dataset, args.version)\n",
    "os.makedirs(path_to_save, exist_ok=True)\n",
    "\n",
    "# cuda\n",
    "if args.cuda:\n",
    "    print('use cuda')\n",
    "    cudnn.benchmark = True\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Dataset Config: CUSTOM_DATASET \n",
      "==============================\n",
      "Model Config: YOWO_V2_LARGE \n"
     ]
    }
   ],
   "source": [
    "d_cfg = build_dataset_config(args)\n",
    "m_cfg = build_model_config(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_jitter(img, jitter):\n",
    "    if random.random() < jitter:\n",
    "        angle = random.uniform(-10, 10)\n",
    "        img = transforms.functional.rotate(img, angle)\n",
    "    return img\n",
    "\n",
    "def adjust_exposure(img, exposure):\n",
    "    img = transforms.functional.adjust_brightness(img, 1 + random.uniform(-exposure, exposure))\n",
    "    return img\n",
    "\n",
    "def img_augmentation(img_size=224, jitter=0.2, hue=0.1, saturation=1.5, exposure=1.5):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.Lambda(lambda x: random_jitter(x, jitter)),\n",
    "        transforms.ColorJitter(hue=hue, saturation=saturation),\n",
    "        transforms.Lambda(lambda x: adjust_exposure(x, exposure)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "augmentation = img_augmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_basetransform(img_size=224, pixel_mean=[0., 0., 0.], pixel_std=[1., 1., 1.]):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=pixel_mean, std=pixel_std)\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "basetransform = img_basetransform()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/longbach/Desktop/motion-det-dataset/processed_data'\n",
    "\n",
    "# Create an instance of your custom dataset with a split ratio of 0.8\n",
    "custom_dataset = CustomDataset(root_dir, transform=augmentation, is_train=True)\n",
    "\n",
    "# Create a data loader for training\n",
    "train_batch_size = 1\n",
    "train_data_loader = DataLoader(custom_dataset, batch_size=train_batch_size, shuffle=True, collate_fn=collate_fn, drop_last=False, pin_memory=True)\n",
    "\n",
    "# Create an instance of your custom dataset with a split ratio of 0.2 for validation\n",
    "val_dataset = CustomDataset(root_dir, transform=basetransform, is_train=False)\n",
    "\n",
    "# Create a data loader for validation\n",
    "val_batch_size = 1\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=False, collate_fn=collate_fn, drop_last=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['ch5_20231207_labels_frame_0320.txt'], tensor([[[[[0.1686, 0.1647, 0.1647,  ..., 0.0471, 0.0471, 0.0471],\n",
      "           [0.1686, 0.1647, 0.1647,  ..., 0.0510, 0.0471, 0.0471],\n",
      "           [0.1686, 0.1686, 0.1647,  ..., 0.0510, 0.0471, 0.0471],\n",
      "           ...,\n",
      "           [0.1137, 0.1294, 0.1412,  ..., 0.0314, 0.0314, 0.0314],\n",
      "           [0.1098, 0.1294, 0.1451,  ..., 0.0314, 0.0314, 0.0314],\n",
      "           [0.1098, 0.1294, 0.1451,  ..., 0.0314, 0.0314, 0.0314]],\n",
      "\n",
      "          [[0.6549, 0.6471, 0.6431,  ..., 0.1804, 0.1725, 0.1804],\n",
      "           [0.6588, 0.6471, 0.6431,  ..., 0.1843, 0.1725, 0.1804],\n",
      "           [0.6667, 0.6549, 0.6431,  ..., 0.1922, 0.1804, 0.1804],\n",
      "           ...,\n",
      "           [0.4235, 0.5020, 0.5412,  ..., 0.1137, 0.1137, 0.1137],\n",
      "           [0.4353, 0.5176, 0.5725,  ..., 0.1098, 0.1137, 0.1137],\n",
      "           [0.4353, 0.5176, 0.5765,  ..., 0.1098, 0.1137, 0.1137]],\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           ...,\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           ...,\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          [[0.5804, 0.5765, 0.5765,  ..., 0.1608, 0.1569, 0.1608],\n",
      "           [0.5843, 0.5765, 0.5765,  ..., 0.1647, 0.1569, 0.1608],\n",
      "           [0.5922, 0.5804, 0.5765,  ..., 0.1725, 0.1608, 0.1608],\n",
      "           ...,\n",
      "           [0.3804, 0.4510, 0.4863,  ..., 0.1020, 0.1020, 0.1020],\n",
      "           [0.3843, 0.4667, 0.5137,  ..., 0.0980, 0.1020, 0.1020],\n",
      "           [0.3922, 0.4667, 0.5176,  ..., 0.0980, 0.1020, 0.1020]],\n",
      "\n",
      "          [[0.9490, 0.9373, 0.9373,  ..., 0.2627, 0.2510, 0.2627],\n",
      "           [0.9569, 0.9373, 0.9373,  ..., 0.2706, 0.2510, 0.2627],\n",
      "           [0.9647, 0.9490, 0.9373,  ..., 0.2784, 0.2627, 0.2627],\n",
      "           ...,\n",
      "           [0.6235, 0.7373, 0.7961,  ..., 0.1686, 0.1686, 0.1686],\n",
      "           [0.6353, 0.7529, 0.8275,  ..., 0.1608, 0.1686, 0.1686],\n",
      "           [0.6353, 0.7529, 0.8392,  ..., 0.1608, 0.1686, 0.1686]]],\n",
      "\n",
      "\n",
      "         [[[0.1882, 0.1882, 0.1882,  ..., 0.0588, 0.0588, 0.0588],\n",
      "           [0.1922, 0.1882, 0.1882,  ..., 0.0627, 0.0588, 0.0588],\n",
      "           [0.1922, 0.1882, 0.1882,  ..., 0.0627, 0.0588, 0.0588],\n",
      "           ...,\n",
      "           [0.1294, 0.1490, 0.1608,  ..., 0.0431, 0.0431, 0.0431],\n",
      "           [0.1216, 0.1451, 0.1569,  ..., 0.0431, 0.0431, 0.0431],\n",
      "           [0.1216, 0.1412, 0.1529,  ..., 0.0431, 0.0431, 0.0431]],\n",
      "\n",
      "          [[0.7686, 0.7647, 0.7569,  ..., 0.2627, 0.2627, 0.2667],\n",
      "           [0.7765, 0.7647, 0.7569,  ..., 0.2667, 0.2627, 0.2667],\n",
      "           [0.7804, 0.7686, 0.7569,  ..., 0.2745, 0.2667, 0.2667],\n",
      "           ...,\n",
      "           [0.5647, 0.6431, 0.6784,  ..., 0.1961, 0.1961, 0.1961],\n",
      "           [0.5255, 0.5961, 0.6588,  ..., 0.1922, 0.1961, 0.1961],\n",
      "           [0.4941, 0.5843, 0.6549,  ..., 0.1922, 0.1843, 0.1843]],\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           ...,\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           ...,\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          [[0.7216, 0.7176, 0.7216,  ..., 0.2392, 0.2353, 0.2392],\n",
      "           [0.7255, 0.7176, 0.7216,  ..., 0.2431, 0.2353, 0.2392],\n",
      "           [0.7333, 0.7216, 0.7216,  ..., 0.2510, 0.2392, 0.2392],\n",
      "           ...,\n",
      "           [0.5059, 0.5765, 0.6118,  ..., 0.1804, 0.1804, 0.1804],\n",
      "           [0.4745, 0.5451, 0.5922,  ..., 0.1765, 0.1765, 0.1765],\n",
      "           [0.4588, 0.5333, 0.5843,  ..., 0.1765, 0.1725, 0.1725]],\n",
      "\n",
      "          [[1.0000, 1.0000, 1.0000,  ..., 0.3882, 0.3804, 0.3882],\n",
      "           [1.0000, 1.0000, 1.0000,  ..., 0.3961, 0.3804, 0.3882],\n",
      "           [1.0000, 1.0000, 1.0000,  ..., 0.4039, 0.3882, 0.3882],\n",
      "           ...,\n",
      "           [0.8196, 0.9294, 0.9882,  ..., 0.2941, 0.2941, 0.2941],\n",
      "           [0.7686, 0.8784, 0.9569,  ..., 0.2863, 0.2863, 0.2863],\n",
      "           [0.7451, 0.8627, 0.9490,  ..., 0.2863, 0.2784, 0.2784]]],\n",
      "\n",
      "\n",
      "         [[[0.1765, 0.1765, 0.1765,  ..., 0.0510, 0.0471, 0.0471],\n",
      "           [0.1804, 0.1765, 0.1765,  ..., 0.0510, 0.0471, 0.0471],\n",
      "           [0.1804, 0.1765, 0.1765,  ..., 0.0549, 0.0471, 0.0471],\n",
      "           ...,\n",
      "           [0.1137, 0.1333, 0.1451,  ..., 0.0353, 0.0353, 0.0353],\n",
      "           [0.1137, 0.1333, 0.1451,  ..., 0.0353, 0.0353, 0.0353],\n",
      "           [0.1137, 0.1333, 0.1451,  ..., 0.0353, 0.0353, 0.0353]],\n",
      "\n",
      "          [[0.8039, 0.8000, 0.8039,  ..., 0.2667, 0.2510, 0.2510],\n",
      "           [0.8118, 0.8000, 0.8039,  ..., 0.2745, 0.2510, 0.2510],\n",
      "           [0.8157, 0.8039, 0.8039,  ..., 0.2784, 0.2510, 0.2510],\n",
      "           ...,\n",
      "           [0.5529, 0.6353, 0.6824,  ..., 0.2039, 0.2039, 0.2039],\n",
      "           [0.5294, 0.6078, 0.6471,  ..., 0.1961, 0.1922, 0.1922],\n",
      "           [0.5137, 0.5961, 0.6431,  ..., 0.1961, 0.1922, 0.1922]],\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           ...,\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           ...,\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          [[0.6627, 0.6588, 0.6745,  ..., 0.1922, 0.1765, 0.1725],\n",
      "           [0.6706, 0.6588, 0.6745,  ..., 0.1961, 0.1765, 0.1725],\n",
      "           [0.6745, 0.6627, 0.6745,  ..., 0.2039, 0.1725, 0.1725],\n",
      "           ...,\n",
      "           [0.4118, 0.4863, 0.5333,  ..., 0.1333, 0.1333, 0.1333],\n",
      "           [0.4235, 0.5020, 0.5333,  ..., 0.1294, 0.1255, 0.1255],\n",
      "           [0.4275, 0.4980, 0.5294,  ..., 0.1294, 0.1294, 0.1294]],\n",
      "\n",
      "          [[1.0000, 1.0000, 1.0000,  ..., 0.3216, 0.2941, 0.2941],\n",
      "           [1.0000, 1.0000, 1.0000,  ..., 0.3294, 0.2941, 0.2941],\n",
      "           [1.0000, 1.0000, 1.0000,  ..., 0.3373, 0.2941, 0.2941],\n",
      "           ...,\n",
      "           [0.6941, 0.8118, 0.8784,  ..., 0.2275, 0.2275, 0.2275],\n",
      "           [0.7020, 0.8196, 0.8706,  ..., 0.2196, 0.2196, 0.2196],\n",
      "           [0.7098, 0.8118, 0.8627,  ..., 0.2196, 0.2196, 0.2196]]]]]), [{'boxes': tensor([[76.9062, 38.1667, 11.1511, 37.1667],\n",
      "        [66.2188, 32.5595, 10.2188, 41.1071]]), 'labels': tensor([0, 1]), 'orig_size': [224, 224], 'video_idx': 'ch5_20231207_labels_frame_0320.txt'}])\n"
     ]
    }
   ],
   "source": [
    "for i in train_data_loader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['ch2_20230712_labels_frame_11552.txt'], tensor([[[[[0.4078, 0.6510, 0.2549,  ..., 0.1176, 0.0902, 0.0902],\n",
      "           [0.6667, 0.4588, 0.0745,  ..., 0.1176, 0.0902, 0.0902],\n",
      "           [0.6431, 0.1686, 0.0706,  ..., 0.1137, 0.0863, 0.0941],\n",
      "           ...,\n",
      "           [0.2392, 0.1569, 0.0471,  ..., 0.1490, 0.1451, 0.1412],\n",
      "           [0.3216, 0.2510, 0.1569,  ..., 0.1608, 0.1529, 0.1451],\n",
      "           [0.2000, 0.3059, 0.2510,  ..., 0.1647, 0.1569, 0.1490]],\n",
      "\n",
      "          [[0.4078, 0.6510, 0.2549,  ..., 0.1176, 0.0902, 0.0902],\n",
      "           [0.6667, 0.4588, 0.0745,  ..., 0.1176, 0.0902, 0.0902],\n",
      "           [0.6431, 0.1686, 0.0706,  ..., 0.1137, 0.0863, 0.0941],\n",
      "           ...,\n",
      "           [0.2392, 0.1569, 0.0471,  ..., 0.1490, 0.1451, 0.1412],\n",
      "           [0.3216, 0.2510, 0.1569,  ..., 0.1608, 0.1529, 0.1451],\n",
      "           [0.2000, 0.3059, 0.2510,  ..., 0.1647, 0.1569, 0.1490]],\n",
      "\n",
      "          [[0.4078, 0.6510, 0.2549,  ..., 0.1176, 0.0902, 0.0902],\n",
      "           [0.6667, 0.4588, 0.0745,  ..., 0.1176, 0.0902, 0.0902],\n",
      "           [0.6431, 0.1686, 0.0706,  ..., 0.1137, 0.0863, 0.0941],\n",
      "           ...,\n",
      "           [0.2392, 0.1569, 0.0471,  ..., 0.1490, 0.1451, 0.1412],\n",
      "           [0.3216, 0.2510, 0.1569,  ..., 0.1608, 0.1529, 0.1451],\n",
      "           [0.2000, 0.3059, 0.2510,  ..., 0.1647, 0.1569, 0.1490]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.4078, 0.6510, 0.2549,  ..., 0.1176, 0.0902, 0.0902],\n",
      "           [0.6667, 0.4588, 0.0745,  ..., 0.1176, 0.0902, 0.0902],\n",
      "           [0.6431, 0.1686, 0.0706,  ..., 0.1137, 0.0863, 0.0941],\n",
      "           ...,\n",
      "           [0.2392, 0.1569, 0.0471,  ..., 0.1490, 0.1451, 0.1412],\n",
      "           [0.3216, 0.2510, 0.1569,  ..., 0.1608, 0.1529, 0.1451],\n",
      "           [0.2000, 0.3059, 0.2510,  ..., 0.1647, 0.1569, 0.1490]],\n",
      "\n",
      "          [[0.4078, 0.6510, 0.2549,  ..., 0.1176, 0.0902, 0.0902],\n",
      "           [0.6667, 0.4588, 0.0745,  ..., 0.1176, 0.0902, 0.0902],\n",
      "           [0.6431, 0.1686, 0.0706,  ..., 0.1137, 0.0863, 0.0941],\n",
      "           ...,\n",
      "           [0.2392, 0.1569, 0.0471,  ..., 0.1490, 0.1451, 0.1412],\n",
      "           [0.3216, 0.2510, 0.1569,  ..., 0.1608, 0.1529, 0.1451],\n",
      "           [0.2000, 0.3059, 0.2510,  ..., 0.1647, 0.1569, 0.1490]],\n",
      "\n",
      "          [[0.4078, 0.6510, 0.2549,  ..., 0.1176, 0.0902, 0.0902],\n",
      "           [0.6667, 0.4588, 0.0745,  ..., 0.1176, 0.0902, 0.0902],\n",
      "           [0.6431, 0.1686, 0.0706,  ..., 0.1137, 0.0863, 0.0941],\n",
      "           ...,\n",
      "           [0.2392, 0.1569, 0.0471,  ..., 0.1490, 0.1451, 0.1412],\n",
      "           [0.3216, 0.2510, 0.1569,  ..., 0.1608, 0.1529, 0.1451],\n",
      "           [0.2000, 0.3059, 0.2510,  ..., 0.1647, 0.1569, 0.1490]]],\n",
      "\n",
      "\n",
      "         [[[0.4824, 0.7412, 0.4196,  ..., 0.2078, 0.1686, 0.1647],\n",
      "           [0.7373, 0.5451, 0.2314,  ..., 0.2078, 0.1686, 0.1647],\n",
      "           [0.7176, 0.2588, 0.2314,  ..., 0.2039, 0.1647, 0.1686],\n",
      "           ...,\n",
      "           [0.2902, 0.2078, 0.0941,  ..., 0.2118, 0.2118, 0.2078],\n",
      "           [0.3647, 0.2902, 0.1961,  ..., 0.2078, 0.2039, 0.1961],\n",
      "           [0.2314, 0.3412, 0.2863,  ..., 0.2078, 0.2000, 0.1922]],\n",
      "\n",
      "          [[0.4824, 0.7412, 0.4196,  ..., 0.2078, 0.1686, 0.1647],\n",
      "           [0.7373, 0.5451, 0.2314,  ..., 0.2078, 0.1686, 0.1647],\n",
      "           [0.7176, 0.2588, 0.2314,  ..., 0.2039, 0.1647, 0.1686],\n",
      "           ...,\n",
      "           [0.2902, 0.2078, 0.0941,  ..., 0.2118, 0.2118, 0.2078],\n",
      "           [0.3647, 0.2902, 0.1961,  ..., 0.2078, 0.2039, 0.1961],\n",
      "           [0.2314, 0.3412, 0.2863,  ..., 0.2078, 0.2000, 0.1922]],\n",
      "\n",
      "          [[0.4824, 0.7412, 0.4196,  ..., 0.2078, 0.1686, 0.1647],\n",
      "           [0.7373, 0.5451, 0.2314,  ..., 0.2078, 0.1686, 0.1647],\n",
      "           [0.7176, 0.2588, 0.2314,  ..., 0.2039, 0.1647, 0.1686],\n",
      "           ...,\n",
      "           [0.2902, 0.2078, 0.0941,  ..., 0.2118, 0.2118, 0.2078],\n",
      "           [0.3647, 0.2902, 0.1961,  ..., 0.2078, 0.2039, 0.1961],\n",
      "           [0.2314, 0.3412, 0.2863,  ..., 0.2078, 0.2000, 0.1922]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.4824, 0.7412, 0.4196,  ..., 0.2078, 0.1686, 0.1647],\n",
      "           [0.7373, 0.5451, 0.2314,  ..., 0.2078, 0.1686, 0.1647],\n",
      "           [0.7176, 0.2588, 0.2314,  ..., 0.2039, 0.1647, 0.1686],\n",
      "           ...,\n",
      "           [0.2902, 0.2078, 0.0941,  ..., 0.2118, 0.2118, 0.2078],\n",
      "           [0.3647, 0.2902, 0.1961,  ..., 0.2078, 0.2039, 0.1961],\n",
      "           [0.2314, 0.3412, 0.2863,  ..., 0.2078, 0.2000, 0.1922]],\n",
      "\n",
      "          [[0.4824, 0.7412, 0.4196,  ..., 0.2078, 0.1686, 0.1647],\n",
      "           [0.7373, 0.5451, 0.2314,  ..., 0.2078, 0.1686, 0.1647],\n",
      "           [0.7176, 0.2588, 0.2314,  ..., 0.2039, 0.1647, 0.1686],\n",
      "           ...,\n",
      "           [0.2902, 0.2078, 0.0941,  ..., 0.2118, 0.2118, 0.2078],\n",
      "           [0.3647, 0.2902, 0.1961,  ..., 0.2078, 0.2039, 0.1961],\n",
      "           [0.2314, 0.3412, 0.2863,  ..., 0.2078, 0.2000, 0.1922]],\n",
      "\n",
      "          [[0.4824, 0.7412, 0.4196,  ..., 0.2078, 0.1686, 0.1647],\n",
      "           [0.7373, 0.5451, 0.2314,  ..., 0.2078, 0.1686, 0.1647],\n",
      "           [0.7176, 0.2588, 0.2314,  ..., 0.2039, 0.1647, 0.1686],\n",
      "           ...,\n",
      "           [0.2902, 0.2078, 0.0941,  ..., 0.2118, 0.2118, 0.2078],\n",
      "           [0.3647, 0.2902, 0.1961,  ..., 0.2078, 0.2039, 0.1961],\n",
      "           [0.2314, 0.3412, 0.2863,  ..., 0.2078, 0.2000, 0.1922]]],\n",
      "\n",
      "\n",
      "         [[[0.4980, 0.7490, 0.4000,  ..., 0.2471, 0.1961, 0.1922],\n",
      "           [0.7529, 0.5608, 0.2588,  ..., 0.2471, 0.1961, 0.1922],\n",
      "           [0.7294, 0.2902, 0.3059,  ..., 0.2431, 0.1922, 0.1961],\n",
      "           ...,\n",
      "           [0.2627, 0.1843, 0.0863,  ..., 0.2078, 0.1922, 0.1843],\n",
      "           [0.3412, 0.2706, 0.1804,  ..., 0.2196, 0.2078, 0.2000],\n",
      "           [0.2157, 0.3216, 0.2667,  ..., 0.2235, 0.2157, 0.2078]],\n",
      "\n",
      "          [[0.4980, 0.7490, 0.4000,  ..., 0.2471, 0.1961, 0.1922],\n",
      "           [0.7529, 0.5608, 0.2588,  ..., 0.2471, 0.1961, 0.1922],\n",
      "           [0.7294, 0.2902, 0.3059,  ..., 0.2431, 0.1922, 0.1961],\n",
      "           ...,\n",
      "           [0.2627, 0.1843, 0.0863,  ..., 0.2078, 0.1922, 0.1843],\n",
      "           [0.3412, 0.2706, 0.1804,  ..., 0.2196, 0.2078, 0.2000],\n",
      "           [0.2157, 0.3216, 0.2667,  ..., 0.2235, 0.2157, 0.2078]],\n",
      "\n",
      "          [[0.4980, 0.7490, 0.4000,  ..., 0.2471, 0.1961, 0.1922],\n",
      "           [0.7529, 0.5608, 0.2588,  ..., 0.2471, 0.1961, 0.1922],\n",
      "           [0.7294, 0.2902, 0.3059,  ..., 0.2431, 0.1922, 0.1961],\n",
      "           ...,\n",
      "           [0.2627, 0.1843, 0.0863,  ..., 0.2078, 0.1922, 0.1843],\n",
      "           [0.3412, 0.2706, 0.1804,  ..., 0.2196, 0.2078, 0.2000],\n",
      "           [0.2157, 0.3216, 0.2667,  ..., 0.2235, 0.2157, 0.2078]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.4980, 0.7490, 0.4000,  ..., 0.2471, 0.1961, 0.1922],\n",
      "           [0.7529, 0.5608, 0.2588,  ..., 0.2471, 0.1961, 0.1922],\n",
      "           [0.7294, 0.2902, 0.3059,  ..., 0.2431, 0.1922, 0.1961],\n",
      "           ...,\n",
      "           [0.2627, 0.1843, 0.0863,  ..., 0.2078, 0.1922, 0.1843],\n",
      "           [0.3412, 0.2706, 0.1804,  ..., 0.2196, 0.2078, 0.2000],\n",
      "           [0.2157, 0.3216, 0.2667,  ..., 0.2235, 0.2157, 0.2078]],\n",
      "\n",
      "          [[0.4980, 0.7490, 0.4000,  ..., 0.2471, 0.1961, 0.1922],\n",
      "           [0.7529, 0.5608, 0.2588,  ..., 0.2471, 0.1961, 0.1922],\n",
      "           [0.7294, 0.2902, 0.3059,  ..., 0.2431, 0.1922, 0.1961],\n",
      "           ...,\n",
      "           [0.2627, 0.1843, 0.0863,  ..., 0.2078, 0.1922, 0.1843],\n",
      "           [0.3412, 0.2706, 0.1804,  ..., 0.2196, 0.2078, 0.2000],\n",
      "           [0.2157, 0.3216, 0.2667,  ..., 0.2235, 0.2157, 0.2078]],\n",
      "\n",
      "          [[0.4980, 0.7490, 0.4000,  ..., 0.2471, 0.1961, 0.1922],\n",
      "           [0.7529, 0.5608, 0.2588,  ..., 0.2471, 0.1961, 0.1922],\n",
      "           [0.7294, 0.2902, 0.3059,  ..., 0.2431, 0.1922, 0.1961],\n",
      "           ...,\n",
      "           [0.2627, 0.1843, 0.0863,  ..., 0.2078, 0.1922, 0.1843],\n",
      "           [0.3412, 0.2706, 0.1804,  ..., 0.2196, 0.2078, 0.2000],\n",
      "           [0.2157, 0.3216, 0.2667,  ..., 0.2235, 0.2157, 0.2078]]]]]), [{'boxes': tensor([[26.2517, 36.4750, 24.1813, 59.5000],\n",
      "        [43.8374, 21.7108, 18.2812, 58.8333]]), 'labels': tensor([0, 1]), 'orig_size': [224, 224], 'video_idx': 'ch2_20230712_labels_frame_11552.txt'}])\n"
     ]
    }
   ],
   "source": [
    "for i in val_data_loader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Build YOWO_V2_LARGE ...\n",
      "==============================\n",
      "2D Backbone: YOLO_FREE_LARGE\n",
      "--pretrained: True\n",
      "==============================\n",
      "FPN: pafpn_elan\n",
      "==============================\n",
      "Head: Decoupled Head\n",
      "==============================\n",
      "Head: Decoupled Head\n",
      "==============================\n",
      "Head: Decoupled Head\n",
      "Loading 2D backbone pretrained weight: YOLO_FREE_LARGE\n",
      "==============================\n",
      "3D Backbone: RESNEXT101\n",
      "--pretrained: True\n",
      "Loading pretrained weight ...\n",
      "Loading 3D backbone pretrained weight: RESNEXT101\n",
      "==============================\n",
      "Head: Decoupled Head\n",
      "==============================\n",
      "Head: Decoupled Head\n",
      "==============================\n",
      "Head: Decoupled Head\n",
      "==============================\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv3d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm3d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool3d'>.\n",
      "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "==============================\n",
      "FLOPs : 53.53 G\n",
      "Params : 109.65 M\n"
     ]
    }
   ],
   "source": [
    "model, criterion = build_model(\n",
    "    args=args,\n",
    "    d_cfg=d_cfg,\n",
    "    m_cfg=m_cfg,\n",
    "    device=device,\n",
    "    num_classes=5, \n",
    "    trainable=True,\n",
    "    resume=args.resume\n",
    "    )\n",
    "model = model.to(device).train()\n",
    "\n",
    "# DDP\n",
    "model_without_ddp = model\n",
    "if args.distributed:\n",
    "    model = DDP(model, device_ids=[args.gpu])\n",
    "    model_without_ddp = model.module\n",
    "\n",
    "# SyncBatchNorm\n",
    "if args.sybn and args.distributed:\n",
    "    print('use SyncBatchNorm ...')\n",
    "    model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "\n",
    "# Compute FLOPs and Params\n",
    "if distributed_utils.is_main_process():\n",
    "    model_copy = deepcopy(model_without_ddp)\n",
    "    FLOPs_and_Params(\n",
    "        model=model_copy,\n",
    "        img_size=d_cfg['test_size'],\n",
    "        len_clip=args.len_clip,\n",
    "        device=device)\n",
    "    del model_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Optimizer: adamw\n",
      "--momentum: 0.9\n",
      "--weight_decay: 0.0005\n",
      "==============================\n",
      "WarmUpScheduler: linear\n",
      "--base_lr: 0.0001\n",
      "--warmup_factor: 0.00066667\n",
      "--wp_iter: 500\n"
     ]
    }
   ],
   "source": [
    "# optimizer\n",
    "base_lr = d_cfg[\"base_lr\"]\n",
    "accumulate = d_cfg[\"accumulate\"]\n",
    "optimizer, start_epoch = build_optimizer(d_cfg, model_without_ddp, base_lr, args.resume)\n",
    "\n",
    "# lr scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, d_cfg[\"lr_epoch\"], d_cfg[\"lr_decay_ratio\"])\n",
    "\n",
    "# warmup scheduler\n",
    "warmup_scheduler = build_warmup(d_cfg, base_lr=base_lr)\n",
    "\n",
    "# training configuration\n",
    "max_epoch = d_cfg[\"max_epoch\"]\n",
    "epoch_size = 10\n",
    "warmup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_log(lr, epoch, max_epoch, iter_i, epoch_size, loss_dict, time, accumulate):\n",
    "    # basic infor\n",
    "    log =  '[Epoch: {}/{}]'.format(epoch+1, max_epoch)\n",
    "    log += '[Iter: {}/{}]'.format(iter_i, epoch_size)\n",
    "    log += '[lr: {:.6f}]'.format(lr[0])\n",
    "    # loss infor\n",
    "    for k in loss_dict.keys():\n",
    "        if k == 'losses':\n",
    "            log += '[{}: {:.2f}]'.format(k, loss_dict[k] * accumulate)\n",
    "        else:\n",
    "            log += '[{}: {:.2f}]'.format(k, loss_dict[k])\n",
    "\n",
    "    # other infor\n",
    "    log += '[time: {:.2f}]'.format(time)\n",
    "\n",
    "    # print log infor\n",
    "    print(log, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "selected index k out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(video_clips)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# loss\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m losses \u001b[38;5;241m=\u001b[39m loss_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlosses\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# reduce            \u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/YOWOv2/models/yowo/loss.py:104\u001b[0m, in \u001b[0;36mCriterion.__call__\u001b[0;34m(self, outputs, targets)\u001b[0m\n\u001b[1;32m     96\u001b[0m     fg_mask \u001b[38;5;241m=\u001b[39m conf_preds\u001b[38;5;241m.\u001b[39mnew_zeros(num_anchors)\u001b[38;5;241m.\u001b[39mbool()\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m     (\n\u001b[1;32m     99\u001b[0m         gt_matched_classes,\n\u001b[1;32m    100\u001b[0m         fg_mask,\n\u001b[1;32m    101\u001b[0m         pred_ious_this_matching,\n\u001b[1;32m    102\u001b[0m         matched_gt_inds,\n\u001b[1;32m    103\u001b[0m         num_fg_img,\n\u001b[0;32m--> 104\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatcher\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfpn_strides\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfpn_strides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43manchors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43manchors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_conf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconf_preds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_cls\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcls_preds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_box\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbox_preds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtgt_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_bboxes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtgt_bboxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     conf_target \u001b[38;5;241m=\u001b[39m fg_mask\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    115\u001b[0m     box_target \u001b[38;5;241m=\u001b[39m tgt_bboxes[matched_gt_inds]\n",
      "File \u001b[0;32m~/miniconda3/envs/conai/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/YOWOv2/models/yowo/matcher.py:80\u001b[0m, in \u001b[0;36mSimOTA.__call__\u001b[0;34m(self, fpn_strides, anchors, pred_conf, pred_cls, pred_box, tgt_labels, tgt_bboxes)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m score_preds_\n\u001b[1;32m     69\u001b[0m cost \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     70\u001b[0m     pair_wise_cls_loss\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3.0\u001b[39m \u001b[38;5;241m*\u001b[39m pair_wise_ious_loss\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m100000.0\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m~\u001b[39mis_in_boxes_and_center)\n\u001b[1;32m     73\u001b[0m ) \u001b[38;5;66;03m# [N, Mp]\u001b[39;00m\n\u001b[1;32m     75\u001b[0m (\n\u001b[1;32m     76\u001b[0m     num_fg,\n\u001b[1;32m     77\u001b[0m     gt_matched_classes,         \u001b[38;5;66;03m# [num_fg,]\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     pred_ious_this_matching,    \u001b[38;5;66;03m# [num_fg,]\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     matched_gt_inds,            \u001b[38;5;66;03m# [num_fg,]\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamic_k_matching\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpair_wise_ious\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtgt_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_gt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfg_mask\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m pair_wise_cls_loss, cost, pair_wise_ious, pair_wise_ious_loss\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     90\u001b[0m         gt_matched_classes,\n\u001b[1;32m     91\u001b[0m         fg_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m         num_fg,\n\u001b[1;32m     95\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/YOWOv2/models/yowo/matcher.py:177\u001b[0m, in \u001b[0;36mSimOTA.dynamic_k_matching\u001b[0;34m(self, cost, pair_wise_ious, gt_classes, num_gt, fg_mask)\u001b[0m\n\u001b[1;32m    175\u001b[0m dynamic_ks \u001b[38;5;241m=\u001b[39m dynamic_ks\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gt_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_gt):\n\u001b[0;32m--> 177\u001b[0m     _, pos_idx \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtopk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcost\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgt_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_ks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgt_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlargest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     matching_matrix[gt_idx][pos_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m topk_ious, dynamic_ks, pos_idx\n",
      "\u001b[0;31mRuntimeError\u001b[0m: selected index k out of range"
     ]
    }
   ],
   "source": [
    "# start to train\n",
    "t0 = time.time()\n",
    "for epoch in range(start_epoch, max_epoch):\n",
    "    if args.distributed:\n",
    "        train_data_loader.batch_sampler.sampler.set_epoch(epoch)            \n",
    "\n",
    "    # train one epoch\n",
    "    for iter_i, (frame_ids, video_clips, targets) in enumerate(train_data_loader):\n",
    "        ni = iter_i + epoch * epoch_size\n",
    "\n",
    "        # warmup\n",
    "        if ni < d_cfg['wp_iter'] and warmup:\n",
    "            warmup_scheduler.warmup(ni, optimizer)\n",
    "\n",
    "        elif ni == d_cfg['wp_iter'] and warmup:\n",
    "            # warmup is over\n",
    "            print('Warmup is over')\n",
    "            warmup = False\n",
    "            warmup_scheduler.set_lr(optimizer, lr=base_lr, base_lr=base_lr)\n",
    "\n",
    "        # to device\n",
    "        video_clips = video_clips.to(device)\n",
    "\n",
    "        # inference\n",
    "        outputs = model(video_clips)\n",
    "        \n",
    "        # loss\n",
    "        loss_dict = criterion(outputs, targets)\n",
    "        losses = loss_dict['losses']\n",
    "\n",
    "        # reduce            \n",
    "        loss_dict_reduced = distributed_utils.reduce_dict(loss_dict)\n",
    "\n",
    "        # check loss\n",
    "        if torch.isnan(losses):\n",
    "            print('loss is NAN !!')\n",
    "            continue\n",
    "\n",
    "        # Backward\n",
    "        losses /= accumulate\n",
    "        losses.backward()\n",
    "\n",
    "        # Optimize\n",
    "        if ni % accumulate == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "        # Display\n",
    "        if distributed_utils.is_main_process() and iter_i % 10 == 0:\n",
    "            t1 = time.time()\n",
    "            cur_lr = [param_group['lr']  for param_group in optimizer.param_groups]\n",
    "            print_log(cur_lr, epoch,  max_epoch, iter_i, epoch_size,loss_dict_reduced, t1-t0, accumulate)\n",
    "        \n",
    "            t0 = time.time()\n",
    "\n",
    "    lr_scheduler.step()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
